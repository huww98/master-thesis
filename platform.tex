\chapter{多视角人脸数据采集平台}
\label{chap:platform}

在上一章的最后，本文提到了若要解决从单张图像同时重建人脸3D模型的几何和材质细节这一高度非适定的问题，则需要更多有关人脸的先验知识。
现有方法通常通过大量高精度的3D数据以训练神经网络模型来建模这种先验。
这些高精度的数据有时候以启发式的算法从2D图像中生成，
但更加鲁棒和贴近物理的方法自然是使用高精度的设备直接采集获得。

然而，可用于实现人脸几何和材质细节高精度重建的设备通常价格高昂，其采集的数据往往也由于商业价值较高而不被公开。
因此，不论是采集高精度的数据以重建高精度模型直接用于下游任务，还是用于建立先验以实现更高效的3D人脸重建，都离不开一套精准、高效、可靠的采集平台。

本章将介绍一套在较为有限的经济和时间成本下实现的多视角人脸数据采集平台。
该平台尽量使用可在市面上购买的部件，以减少对相关专业知识的需求。
同时配合一些定制的软件和硬件，实现对各个部件的高效统筹控制，为高精度重建所需的数据采集全流程提供支持。

\section{总体目标}

本文在设计和搭建该采集平台时，主要考虑了以下几个目标：
\begin{itemize}
\item 低硬件专业技能需求。本项目作为软件学院个人参与的项目，其所能得到的机械、结构、电子等方面的专业技术支持非常有限。
因此，为了能在有限的时间内完成该项目，本文尽可能地使用市面上可购买的部件，以减少对相关专业知识的需求。
虽然如此，本文还是使用了少量定制的硬件。

\item 高精度。高精度的数据是高精度3D重建的基础。
因此，对误差的控制贯穿与采集流程的各个环节，指导整个采集平台的软硬件设计。

\item 高效。整个平台在使用时，特别是在对被拍摄对象拍照时，应该尽可能地快速，以为大规模收集数据集提供可能。

\item 灵活。本平台作为一个主要用于研究性工作的采集平台，其需要具有一定的灵活性，以便应对研究中多变的需求。
基本地，该平台应能同时支持被动光源和主动光源的采集，能灵活配置相机和光源的位置和其他相关参数。

\item 可扩展。即使在本文写作完成后，该平台仍很可能被继续用于后续的研究工作。因此本平台也应适当考虑未来可能的更大规模的采集需求。

\end{itemize}

利用本平台采集的数据预计可用于多种3D人脸重建算法，例如本文其他部分介绍的基于可微分渲染的逆渲染方法。
同时也可用于如多目立体等传统的计算机视觉算法。

本章的主要贡献在于对该平台各个部分的设计和实现，以及对其性能的评估验证。
本章的剩余内容将具体介绍该平台的各个部分。

\section{整体结构设计}

本平台的硬件框架结构设计主要是参考了\citet{RiviereGBGB20}所展示的布局。
首批配置了12台相机和4台带有柔光箱的摄影灯，其中相机固定在3个铝型材搭建的、定制的、高自由度可调节的支架上。
灯则由于其体积质量较大，且市面上缺少相应的单独连接件产品，无法稳固地固定在支架上，因此直接使用了单独的专用灯架固定，以确保安全。
图\ref{fig:HDRI}展示了该平台硬件的整体布局。

\begin{figure}
\centering
\begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[height=7cm]{figures/frame-design}
    \caption{设计图}
\end{subfigure}
\begin{subfigure}[b]{0.2\textwidth}
    \centering
    \includegraphics[height=7cm]{figures/frame-impl}
    \caption{组装完成照片}
\end{subfigure}
\begin{subfigure}[b]{0.47\textwidth}
    \centering
    \includegraphics[height=7cm]{figures/frame-camera}
    \caption{相机固定}
\end{subfigure}
\caption{铝型材支架的设计和实现}
\label{fig:frame}
\end{figure}

图\ref{fig:frame}展示了铝型材支架的设计和实现。
单个支架的主体部分由4个2寸脚轮，12.47米3030铝型材以及若干连接件组成。
设计全高2.103米，长1.06米，宽0.53米。
其物料成本约需要700元。
考虑到实验场地可能的变动，支架装配有4个脚轮，方便移动，且这些脚轮带有锁定功能，在使用时也能固定支架的位置。
脚轮固定在矩形底座上，底座则通过大量连接件，尽可能稳固地支撑了两根2米长的竖直铝型材。
在竖杆之间设计有4根长1米的横杆。
每两根间设计间距为0.5米，但得益于本方案使用T型螺母固定，无需打孔，因此这些横杆的位置可根据需要随时调整。

相机可固定在任意竖杆和横杆上的任意位置。
为固定相机，本方案首先将T型连接板通过T型螺母固定在铝型材上，然后将一个球形云台通过1/4英寸螺栓固定在连接板上，最后将相机通过标准的1/4英寸接口固定在云台上。
使用云台可允许相机以三个自由度任意旋转，再加上相机固定位置，横杆位置，以及支架整体的移动，相机最终固定位置的可调节自由度非常高。

总的来说，该支架支撑稳定，使用灵活，完全满足了固定12台相机的需求，为其他部分的实现打下了良好的基础。
同时，通过增加横杆，或增加支架数量的方式，也可以扩展更多相机固定位置。

\section{被动相机同步}
\label{sec:passive_sync}

本方案使用的是CVTE提供的12台消费级微单相机，型号为佳能R6。
将这些相机固定在支架上后，下一步就需要对它们集中进行控制。
其中最简单的形式就是使它们精确地在同一时刻触发快门，以确保后期重建过程不会受到被拍摄对象的位移或形变影响。
为此，本方案中设计了一种用于相机同步的硬件装置。
该装置构造简单，且无须独立供电。它能以很高的时间精度同时触发多台相机的对焦和快门，从而实现人脸多视角数据的捕获。

\paragraph{相机快门触发原理}

为设计该装置，本文首先调查了所使用的相机所有可能的快门触发方式，包括：
\begin{itemize}
\item 相机机身上的快门按钮。该按钮半按可触发对焦，全按可触发快门。
然而使用机械方式触发快门对自动化控制系统来说显然过于复杂，且容易造成不必要的机械震动。
\item 网络接口。该相机支持连接WiFi，并可通过佳能的私有协议或者基于HTTP的Camera Control API控制。
但是无线网络连接会引入毫秒级别的不确定性延迟，因此不适合用于本方案中高精度的同步控制。
\item 快门线接口。该相机支持通过2.5mm快门线接口触发快门，该接口仅需要简单地控制电路通断即可触发对焦和快门。
\item USB连接。该相机支持通过USB连接上游设备，且可通过佳能的私有协议控制。
该方案虽然可以实现更多控制功能，且USB还能直接为相机供电，
但相比上一种方案，上游设备的开发过于复杂，且佳能官方仅提供了Windows平台的SDK，更提高了开发难度。
\end{itemize}
基于这些考虑，本方案最终使用了快门线接口作为相机同步的触发方式。

用于快门线接口的2.5mm插头如图\ref{fig:2.5mm}所示。
该插头的接触部分呈旋转对称的柱体，柱体不同高度上分布有3个独立的接触区域，分别对应对焦控制、快门控制和地线。
其中两根控制线待机时为带有上拉的输入端口，电压为3.3v。当其与地线短接，从而拉至低电平时，即可触发对应的控制。
此外，当手动按下相机快门按钮时，这些控制线也可输出低电平，以控制其他外设。

\begin{figure}
\centering
\includegraphics[height=2cm]{figures/2.5mm}
\caption{快门线接口的2.5mm插头}
\label{fig:2.5mm}
\end{figure}

\paragraph{被动同步装置设计}
如上所述，若要控制所有相机同时触发快门，则仅需将所有相机的快门控制线连接到同一个按钮上，在按下该按钮时，使控制线和地线短接即可。
但其中设计的难点在于，被控制的相机数量较多，有12台且可能在未来进一步扩展，且相机在空间上较为分散。
因此，为了节约线材，并提升操作的便捷性和装置的可扩展性，本方案设计了一种可串联的相机控制器。
控制器与控制器，控制器与相机间的连接拓扑如图\ref{fig:passive_sync_topo}所示。
\begin{figure}
\centering
\includegraphics[height=5cm]{figures/passive_sync_topo}
\caption{被动同步装置的拓扑结构}
\label{fig:passive_sync_topo}
\end{figure}
控制器间可以任意方式连接，构成星型、树形或链式等多种不同拓扑，每个控制器最多能与3个其他控制器以及8台相机相连。
该结构可通过增加控制器的方式近乎无限扩展，从而实现对更多相机的控制。
此外，每个控制器上都是对等的，通过任意一个控制器上的按钮均可控制所有相机，提升了系统操作的便捷性。

\begin{figure}
\includegraphics[width=\textwidth]{figures/passive_sync_schematic}
\caption{被动控制器的电路原理图}
\label{fig:passive_sync_schematic}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=5cm]{figures/passive_sync_controller}
\caption{被动控制器的实物图}
\end{figure}

其中，每个控制器的原理图如图\ref{fig:passive_sync_schematic}所示。
控制器无需供电，它采用机械按钮的形式完成控制线和底线的短接，从而触发相机快门。
控制器之间，以及相机与控制器间均采用AWG28规格的排线连接，
在控制器端均使用了冷压的XH2.54插头；
在相机段则使用了焊接的2.5mm插头。
此外，每个相机接口在连接到总线前均使用了两颗二极管进行隔离，以防止相机间的干扰。
这样可允许在控制器连接时依然可以手动控制单台相机的快门，也能防止在线缆连接时误触发快门。

\paragraph{同步精度测试}

\begin{figure}
\centering
\begin{subfigure}[b]{0.55\textwidth}
    \includegraphics[width=\textwidth]{figures/passive_sync_test}
    \caption{测试过程示意图}
\end{subfigure}%
\begin{subfigure}[b]{0.44\textwidth}
    \includegraphics[width=\textwidth]{figures/LED_array}
    \caption{单片机和LED阵列}
\end{subfigure}%
\caption{被动同步装置的同步精度测试装置}
\label{fig:passive_sync_test}
\end{figure}

电场的传播速度非常快，因此，当控制器的按钮被按下时，理论上控制信号能同时送达所有相机。
为了实际测试该装置的效果，本文进行了端到端的同步精度测试。
如图\ref{fig:passive_sync_test}所示，该测试的拍摄目标包括5个由单片机控制的LED灯，以及一个60Hz刷新率的显示器（此处使用iPad）。
其中单片机通过硬件计时器中断精确控制LED灯，每个LED灯的亮灭切换间隔依次为0.5ms、1ms、2ms、4ms、8ms，每16ms这些LED灯的状态完成一次循环。
显示器则显示一个秒表，用于判断16ms以上的时间间隔。

相机拜摆放时，需要使LED灯在不同相机传感器的同一位置成像，以避免滚动快门的影响。
拍摄前，需要将快门速度调整为最快的1/4000秒，以尽量避免相机曝光过程与LED的亮灭切换过程重叠，影响读取LED灯的状态。
测试时，将两台相机连接在控制器上，然后多次使用控制器触发快门。
读取结果时，首先丢弃难以判断LED灯状态的图像，
对剩余图像以二进制编码的形式记录LED灯的状态以及屏幕显示的秒表的时间。
对比同一次快门中不同相机拍摄到的照片中读数即可准确获得两台相机曝光的时间差，即控制器的同步精度。

实验结果显示，多台佳能R6相机间的同步精度小于0.5ms，即每次拍摄中不同相机的读数均相同。该精度已经足够满足实际应用的需求，且已经远高于快门滚动的速度。
因受到相机最高快门速度的限制，未能以更高的精度完成测试。
此外，本文也测试了R6和另一台佳能90D单反相机间同步的精度，结果显示两台相机间有4ms但非常稳定的延迟。

\input{calib}

\section{基于反射球的光源标定和HDRI合成}

除了相机外，在实验室中拍摄，环境光照信息也可以提前采集，从而获得比用算法从人脸照片中估计更精准的结果。
这些信息可用于后续逆渲染的优化之中。
如前文所述，本装置使用的照明为4盏带有柔光箱的摄影灯，均布置在被拍摄对象正面180°的范围内。光源标定的目的是获取被拍摄对象所处的空间中的每个位置上来自每个方向的光照强度，即光场信息。
但本设备的柔光箱据被拍摄对象约1.5米远，相比来说，人脸的尺度较小，因此，本文假设所有光线均来自无限远，即该光场的分布近似于与空间位置无关而只与光线入射方向有关。

光照强度和方向的对应关系可被编码在一张HDRI图像（High Dynamic Range Image，高动态范围图像）中，该图像中的每个像素点对应于一个方向，像素点的颜色值则对应于该方向上的光照强度和频率分布。
其与普通的照片保存格式不同，之所以称之为是高动态范围，是因为其每个像素点的颜色值通常作为浮点数保存，因此可以同时记录很强和很弱的光照，同时保持较高的精度。
使用该技术编码的光照信息也常被用于计算机图形学领域。
如图\ref{fig:HDRI}是一张以本节所述方法合成的，记录了本文目前实验环境的HDRI图像。
\begin{figure}
\centering
\TODO{HDRI图像}
% \includegraphics[width=\textwidth]{figures/HDRI}
\caption{实验环境全景HDRI图像}
\label{fig:HDRI}
\end{figure}

\paragraph{数据采集}
为了收集用于合成HDRI的数据，本文将一个全镜面金属的反射球放置于原被拍摄对象头部的位置，然后通过WiFi控制一台靠近中心的相机，继续固定对焦和光圈设置，改变其快门速度和ISO，以捕获该球不同曝光的照片。
通常拍摄的相邻两张照片亮度相差约一倍，共拍摄约8张照片。
这是因为相机的传感器所能记录的最大光照强度是有限的，而若只使用更低的曝光，则由于信噪比的下降，导致最终合成的HDRI中的噪声更多。
使用多种不同的曝光参数拍摄即可同时保留亮部和暗部的细节。
后续步骤将直接使用原始Bayer格式的照片，尽可能保留其中信息，同时获取准确的噪声等级估计。

\paragraph{HDRI合成}
该步骤的目的是将上述拍摄的多张照片中各自最可靠的部分（信噪比高，且未超出传感器量程范围）融合为一张HDRI。
为此，本文设计了一种类似卡尔曼滤波的融合算法。
其基本思想是：将不同照片中的同一像素点的读数视为对同一光照强度的不同测量值，并有不同的测量噪声方差，据此对多个观测值加权平均，得到最可能接近真值的估计值。

本方案使用的相机的传感器中包含了约50万个完全不接受入射光线的像素，这些像素可用于估计黑场（即完全无入射光线时传感器的读数）和测量噪声的方差。
由于数据量非常充裕，这里对每张照片和每个通道分别进行了估计。
计照片$i$中通道$c\in\{\mathrm{r},\mathrm{g1},\mathrm{g2},\mathrm{b}\}$的黑场为$b_{i,c}$，方差为$\sigma_{i,c}^2$。
然后，根据拍摄参数计算每张照片的相对亮度，该值与拍摄的曝光时间和ISO设置成正比。
并将照片据此由暗到亮排序为$\mathcal{I}^{(1)}, \mathcal{I}^{(2)}, \cdots, \mathcal{I}^{(n)}$。
由于原始照片中记录的传感器读数和实际光照强度呈很好的线性关系，
因此可根据读数在每两张相邻照片间通过最小二乘法计算其准确的相对亮度比例：
\begin{equation}
r_i^* = \argmin_{r_i} \sum_{j|\mathcal{I}^{(i+1)}_j < \xi} \left[r_i (\mathcal{I}^{(i)}_j - b_{i,c}) - (\mathcal{I}^{(i+1)}_j - b_{i+1,c})\right]^2
\text{，}
\end{equation}
其中$\xi$为使用ExifTool读取的“线性上界”(Linearity Upper Margin)，$j$为像素索引。
该问题为线性最小二乘，可直接求其解析解。
该比例理论上应与之前从拍摄参数计算的值相同，但实际可能由于相机校准误差或其他原因而有所偏差。
\begin{figure}
\centering
\import{build/figures}{HDRI_stats.pgf}
\caption[HDRI输入照片读数统计]{HDRI输入照片读数统计。
(a)展示了相邻曝光的两张照片中同一位置的像素值之间的对应关系，其背景的直方图表示较暗照片像素数量在不同像素值上的分布。
可见在超出量程前它们具有很好的线性关系，但通过曝光时间估计的亮度比例与实际有明显偏差。
(b)展示了观测噪音与ISO设定间的关系。}
\label{fig:HDRI_stat}
\end{figure}
如图\ref{fig:HDRI_stat}a展示了其中一对照片的读数对应关系，可见实际拟合的比例与从拍摄参数计算的有明显偏差。
最后根据这些相对值$r_i^*$，令任意照片的亮度系数为$1$，可求得所有照片的亮度系数$e_i$。

有趣的是，虽然理论上ISO越高则噪声水平将越高，但本方案使用的相机在ISO从200增加至400时噪声水平却无明显上升，反而是黑场由512上升到了2048。由此可以推测或许相机在这两种不同配置时处于不同的工作模式。

在获得了这些参数后，假设观测噪声服从高斯分布，即可从暗到亮递推地合成HDRI。合成的过程可表示为：
\begin{equation}
\begin{aligned}
    \mathcal{J}^{(1)} &= e_1 \left(\mathcal{I}^{(1)} - b_{1,c}\right),\quad
    \hat{\sigma}_{1,c}^2 = e_1^2 \sigma_{1,c}^2 \\
    \mathcal{J}^{(i)}_j &= \begin{cases}
    \frac{e_i^2 \sigma_{i,c}^2 \mathcal{J}^{(i-1)}_j + \hat{\sigma}_{i-1,c}^2 e_i \left(\mathcal{I}^{(i)}_j - b_{i,c}\right)}{\hat{\sigma}_{i-1,c}^2 + e_i^2 \sigma_{i,c}^2} & \text{if } \mathcal{I}^{(i)}_j < \xi \\
    \mathcal{J}^{(i-1)}_j & \text{otherwise}
    \end{cases}\\
    \hat{\sigma}_{i,c}^2 &= \frac{e_i^2 \hat{\sigma}_{i-1,c}^2 \sigma_{i,c}^2}{\hat{\sigma}_{i-1,c}^2 + e_i^2 \sigma_{i,c}^2}
    \quad (i > 1)\text{，}
\end{aligned}
\end{equation}
其中$\mathcal{J}$为每步合成的照片，$\mathcal{J}^{(n)}$即为最终所需的HDRI。
该递推过程与卡尔曼滤波中的融合新的观测值的过程类似，且可以由贝叶斯公式导出，即通过以$\mathcal{J}^{(i-1)}$为均值的先验分布，融合以$e_i\left(\mathcal{I}^{(i)} - b_{i,c}\right)$为均值的观测，推导以$\mathcal{J}^{(i)}$为均值的后验分布。

该融合过程具有以下理想的性质：
较暗的照片信噪比较高，其由于具有较大的$e_i$而在合成时方差较大，从而权重更低；
照片中超出传感器量程（$\geq\xi$）的部分则完全不会影响合成结果；
ISO较高的照片由于噪声方差较大（如图\ref{fig:HDRI_stat}b），也能自动在合成中降低权重。
\pdfcomment{TODO 在照片的方差计算中加入photon noise，这是像素较亮时的主导噪音}

\paragraph{像素重映射}
在上一步我们获得了一张反射球的HDRI照片，这张照片中记录了环境中几乎所有方向的光照信息（除了被球挡住的方向）。
但我们仍然需要一种方法将环境光照的方向映射到该照片中的像素坐标上，以便于在渲染时使用。
该映射取决于诸多因素，如用于拍摄的相机的内外参，球在照片中的位置等。
本方案将结合第\ref{sec:camera_calib}节输出的相机参数，使用一种半自动化的方式完成该映射。

首先，为了准确得到反射球在照片中的位置，本方案开发了一款标注工具以允许用户手动选中球的位置，如图\ref{fig:sphere_locator}所示。
该工具在上部将显示经过畸变校正的照片，用户可以自由缩放和平移，以及改变照片的亮度以便观察。在照片上叠加显示了当前选中的球位置的轮廓。
在下部显示了三组滑块，分别用于调整轮廓的左边界、右边界和上边界在照片中的位置。每组滑块分为粗调和细调两部分，细条滑块允许用户在粗调结果周围10像素进一步细化结果。
需要注意的是，这里显示的球的轮廓虽然很接近，但并不是一个圆形。为了尽可能精确，本文将解算后球的位置按照标定的参数重新投影到照片上，进而获取该轮廓。

在获得了用户输入的左、右、上三个在畸变校正后的像素坐标下的参数后，本文将通过以下算法解算球在相机坐标系下的位置。
首先，由于本文假设光线来自无限远处，因此最终坐标映射的结果将和球的尺度无关，不妨将球的半径设为1。
用户指定的三个参数可各确定一个于球相切的平面的方程，以球心到三个面的距离分别为1联立方程，即可求解出球心的坐标。

\begin{wrapfigure}{r}{4cm}
\begin{tikzpicture}
    \filldraw[black] (0,0) circle (2pt) node[anchor=west]{相机$\mathbf{O}$};
    \draw (0,0) -- (0,1.5) node[right=-1mm] {$f_x$} -- (0,2);
    \draw (0,0) -- (-2,2);
    \draw (0,0) -- (2,2);
    \draw [name path=H] (-2,2) -- node[below] {$c_x$} (0,2) -- (2,2);

    \coordinate (C) at (0.3, 3.3);
    \filldraw (C) circle (2pt) node[anchor=west]{$\mathbf{C}$};
    \node[draw, circle] (c) at (C) [minimum size=2.4cm] {};
    \coordinate (A) at (tangent cs:node=c,point={(0,0)},solution=1);
    \coordinate (B) at (tangent cs:node=c,point={(0,0)},solution=2);
    \draw [name path=P1] (0,0) -- ($(0,0)!4cm!(A)$);
    \draw [name path=P2] (0,0) -- ($(0,0)!4cm!(B)$);

    \path [name intersections={of=P1 and H,by=I1}];
    \path [name intersections={of=P2 and H,by=I2}];
    \filldraw (I1) circle (2pt);
    \filldraw (I2) circle (2pt);

    \node [above] at ($(-2,2)!0.5!(I2)$) {$l$};
\end{tikzpicture}
\end{wrapfigure}
右图为整个场景的俯视图，其中下方的三角形代表相机的视锥体，图中标注了相机经过标定后的焦距$f_x$和光心$c_x$。上方的圆代表反射球，两条切线分别表示由用户输入确定的左，右两个平面。
下面根据用户输入的像素坐标$l$求解左平面的法向量$\mathbf{n}_l$。
取点$A = (l-c_x, 1, f_x)$、$B = (l-c_x, 0, f_x)$。
可以验证该两点均投影在像素横坐标为$l$的位置（图中左侧实心点处），
于是可以通过点$O$、$A$、$B$确定该平面，其法向量为
\begin{equation}
\mathbf{n}_l = \overrightarrow{\mathbf{O}\mathbf{A}} \times \overrightarrow{\mathbf{O}\mathbf{B}}
= \left[f_x, 0, c_x - l\right]
\text{。}
\end{equation}
同理可以求得右平面和上平面的法向量$\mathbf{n}_r$、$\mathbf{n}_u$。
记球心坐标为$\mathbf{C}$。
球心到左平面的距离为1可表示为：
\begin{equation}
    \frac {\overrightarrow{\mathbf{O}\mathbf{C}} \cdot \mathbf{n}_l}{\|\mathbf{n}_l\|} = 1
    \text{。}
\end{equation}
对于另外两个平面同理可列方程。
解该线性方程组即可得到球心的坐标$\mathbf{C}$。

在解算出反射球的具体位置后，需要将其重新投影到照片上并绘制出轮廓，以便用户得到实时的反馈。
为此，本方案进一步求该轮廓的参数方程以便绘制。
令曲线参数方程的参数为$\theta\in[0, 2\pi]$。
设球面上一点$\mathbf{D} = \mathbf{C} + [\cos\theta \cos\phi, \sin\theta \cos\phi, \sin\phi]$，其中$\phi$为未知数。
令$\overrightarrow{OD}$与球面相切，可由$\overrightarrow{\mathbf{O}\mathbf{D}} \perp \overrightarrow{\mathbf{C}\mathbf{D}}$列方程求解$\phi$：
\begin{equation}
\begin{aligned}
&\overrightarrow{\mathbf{O}\mathbf{C}} \cdot \overrightarrow{\mathbf{C}\mathbf{D}} = -1 \\
\Rightarrow &a \cos\phi + \mathbf{C}_z \sin\phi = -1\\
\Rightarrow &\phi = \arcsin\frac{-1}{\sqrt{a^2 + \mathbf{C}_z^2}} - \arctan\frac{a}{\mathbf{C}_z^2}, \quad a = \mathbf{C}_x * \cos(\theta) + \mathbf{C}_y * \sin(\theta)
\text{，}
\end{aligned}
\end{equation}
其中最后一步推导使用了辅助角公式。然后点$D$在像素坐标系中的投影即为所求的反射球的轮廓曲线上的一点，其关于$\theta$的参数方程可用于便捷地绘制出该轮廓。

最后，利用反射球的位置，我们需要解算光照方向与像素坐标的映射关系。
对于像素坐标上的一点$e$，可将其映射为相机坐标系中的一条源自原点射线，其方向为：
\begin{equation}
    \mathbf{v} = \left[\frac{e_x-c_x}{f_x}, \frac{e_y-c_y}{f_y}, 1\right]
    \text{，}
    \label{eq:ray1}
\end{equation}
该方向是视线方向，也即光线从反射球反射的相反方向。
该射线与反射球表面交于一点$\mathbf{E}=\lambda\mathbf{v}$，且满足：
\begin{equation}
    \| \mathbf{E} - \mathbf{C} \| = 1
    \text{。}
    \label{eq:ray2}
\end{equation}
在$\mathbf{E}$处，球面的单位法向量为$\mathbf{n}=\overrightarrow{\mathbf{O}\mathbf{E}}$，视线反射的方向为$\mathbf{r}$。
根据光线反射的原理，$\mathbf{r}$、$\mathbf{v}$、$\mathbf{n}$位于同一平面且入射角等于出射角，有：
\begin{equation}
    \mathbf{r} = \mathbf{v} - 2(\mathbf{v} \cdot \mathbf{n}) \mathbf{n}
    \text{。}
    \label{eq:ray3}
\end{equation}
联立公式\eqref{eq:ray1}至\eqref{eq:ray3}即可获得所求像素坐标$e$与光照方向$\mathbf{r}$的映射关系。
理想中应当对给定的任意$\mathbf{r}$求解其所对应的像素坐标$e$，
但方程组的求解过于复杂，因此本方案选择从像素坐标$e$出发，对每个像素求解其对应的光照方向$\mathbf{r}$。
在使用时，对于任意给定的$\mathbf{r}$，从与其最相近的3个准确对应了某个像素的方向上的光照信息中进行插值。

为了得到可直接在下游任务中使用的环境光照贴图，本方案在照片中反射球所在区域的每个像素处生成一个顶点，并将其连接成三角形网格，从其像素坐标计算每个顶点的纹理坐标，并按照计算的$\mathbf{r}$将其放置在3D单位球上的对应位置，然后使用OpenGL对所生成的网格进行光栅化渲染，在片元着色器中根据纹理坐标对HDRI采样。
根据所需环境光照贴图的格式不同，可使用不同的顶点着色器完成对应的顶点坐标变换。
本项目已支持常见的等距柱状投影（Blender中使用）和立方体贴图（nvdiffrast中使用）两种格式。

图\ref{fig:HDRI}即为使用本方案生成的等距柱状投影格式的环境光照贴图。
从图中可见该图正面质量较好，但背面则有明显变形，精度和分辨率均较低，这是由于背面区域在反射球照片中对应的面积较小。
被反射球本身挡住的一小片区域则完全是黑色。
画面中的局部有一些扭曲，这可能是因为所使用的反射球并不是完美的球形导致的。
未来可通过对反射球的几何形状进行更精细的建模来改善该问题。

\section{主动相机/闪光灯同步}

上述软硬件方案已能支撑被动光源采集的整个流程。
但本平台还希望能加入对主动光源的支持，以便能实验和对比不同重建方法的优劣。
然而，本方案所使用的消费级相机带来了很大的限制：这些相机在照片模式下无法在很短时间内连续拍摄多张照片，而在视频模式下又缺少不同相机间精确同步的方法。
所以本文主要参考了\citet{FyffeGTGD16}的方案，使用多盏闪光灯依次以数毫秒的间隔闪光，并将相机分为多组，每组同步到不同的闪光灯上，以此达成同时捕获不同视角和不同光照的照片的目的，为重建提供更多信息。

为了完成对闪光灯和相机的控制，本方案设计了一个主动相机同步装置。
它带有一个单片机以完成可定制的实时控制，能独立控制每台相机、闪光灯触发延迟，最多可控制24台设备。
以下部分将进一步介绍该装置的设计和使用。

\paragraph{主动同步装置硬件设计}

\paragraph{主动同步装置软件设计}

\paragraph{滚动快门原理}

\paragraph{闪光灯触发延迟快速标定方法}

\section{照片拍摄和整理流程}

\paragraph{同步装置连接与设定}

\paragraph{拍摄采集对象}

\paragraph{相机、光源标定数据采集}

\paragraph{照片拷贝和整理}

\section{初步验证}

作为该实验平台实用性的初步验证，本文利用该平台采集的数据使用传统的计算机视觉方法尝试重建人脸模型。

本文首先使用Colmap完成人脸的稀疏以及稠密点云重建。\TODO{参数调整}

然后，本文使用FlameFitting工具，将FLAME 3D模型配准到稠密点云上，得到初步的人脸几何形状。

然而，该配准的效果并不理想。因此本文使用Blender同时导入点云和几何形状，并手动调整模型顶点位置以完成更精确的配准。

最后，本文通过Unwrap方法，将照片映射到UV空间，每个视角获得一张纹理贴图，再将这些纹理贴图通过以下方式进行融合，最终获得一个带纹理的3D人脸模型。

\TODO{融合方式公式}

\TODO{结果图}

\section{后续工作}

然而，这种方法仅仅是对该平台采集的数据的初步利用，仅发挥了该平台的一小部分价值。
该平台的设计目标是用于运行可微分渲染算法，后续的研究者们将能利用该平台开展诸多基于可微分渲染的研究，例如：
\begin{itemize}
\item 在传统计算机视觉重建的几何形状的基础上，利用可微分渲染算法，实现符合基于物理的渲染(PBR)流程的人脸材质，包括粗糙度、次表面散射等参数。
\item 利用所采集到的HDRI光源信息，基于分离求和近似(split sum approximation)的可微分光栅化渲染算法，直接端到端地同时估计人脸的几何结构和材质。
\item 利用光线追踪方法，进一步考虑全局光照，以估计更加准确的材质。
\item 将本系统所使用的消费级微单相机更换为工业相机，以实现视频帧同步，可将该实验平台扩展为采集人脸动态表情数据。
\end{itemize}
