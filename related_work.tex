\chapter{相关研究综述}
\label{chap:related_work}

本章主要介绍本课题的相关研究和实践工作，
其中包括使用专业设备的多视角高精度3D重建方法，
基于少量自然环境照片的高效3D人脸重建方法，
可微分渲染以及它在人脸重建中的应用。

\section{使用专业设备的多视角高精度3D重建}

这类方法力求通过模型来精确描述被采集对象的形状和材质，从而在重新渲染时表现出很高的逼真度。
这些模型通常能从任意角度，在任意光照环境下重新渲染，以满足影视、游戏等领域的需要。

\begin{figure}
\centering
\begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[height=150pt]{figures/light_stage}
    \caption{实际采集现场}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[height=150pt]{figures/emily_detail_1}
    \caption{重建的几何细节}
\end{subfigure}
\caption[Digital Emily 项目中的 Light Stage]{Digital Emily项目中的Light Stage\cite{DEP}}
\end{figure}

\paragraph{几何形状重建}
几何形状是物体最基本的属性，即物体每个部分在空间中所处的位置。
几何形状重建的基本原理是识别物体同一个部分在不同相机下的匹配关系，然后借助已知的相机参数，以及该部分在不同相机下的像素坐标，计算出该部分在3D空间中的坐标。称为基于视差的方法。

而计算机中描述几何形状的方法有很多种，其中最基本的是点云模型，它保存了大量位于物体表面的点的坐标。
这种表示也是大多数几何重建算法的目标。
最初，\citet{PFM}通过在目标脸上画一些网格，从而允许手动建立格点间的匹配关系，并建立稀疏的点云。
\citet{ss_geo}对多个相机两两之间计算视差图，然后将多组视差图进行融合，并通过约束进一步排除误匹配点，最终得到一个稠密的点云。其中视差图正是两张照片中，像素级别的匹配关系。视差图的构建是分辨率从低到高逐步细化的，并在过程中应用了平滑性、唯一性和顺序性的约束，以消除误匹配点。
这类方法统称为Multi-View Stereo (MVS)。
\citet{DEP}则利用投影仪在目标表面投影彩条图案，以使匹配结果更加鲁棒。
3dMD的商业3D重建解决方案\footnote{https://3dmd.com/}也使用了斑点图案的投影。
D3DFACS\citep{D3DFACS}数据集采用了3dMD的方案。
在匹配过程中，镜面反射的效果会随视角的变化而变化，从而导致匹配结果的不准确。
因此有不少方法\citep{DEP}选择使用偏振将镜面反射的效果去除，从而提高匹配的准确度。
但由于次表面散射的存在，这种方法得到的几何形状会过于平滑。但这或许不是一个问题，因为在后续估计材质的过程中，会再估计更高分辨率的法向。

虽然视差仍然是最广泛使用的方法，其准确度也非常高，但也不乏其他可行的方法。
例如，\citet{MaHPCWD07}使用光度立体的方法，通过多种球面梯度偏振光源的成像效果，重建物体的表面法向。高分辨率的法向信息可与中等分辨率的结构光的结果进行融合，从而获得高分辨率的几何形状，且能避免单纯依靠法线积分带来的累积误差。
\citet{phase_shift}则将相移方法与视差结合，以获得更高的准确度和鲁棒性。
\citet{BJUT3D}选择使用激光扫描仪。
FaceWarehouse\citep{FaceWarehouse}数据集采用了Kinect深度相机。

在得到点云之后，还需要将点云转换为网格，
该网格的拓扑结构应在采集的不同帧间，以及不同人物间保持一致，
以供渲染、人工编辑，动画制作等使用。
该任务的重点在于找到不同帧间的点的匹配关系，从而重建人脸的运动，变形等特征。
很多方法\citep{PFM,DEP,BickelBAMOPG07}通过在脸上画上易于识别的标记点以辅助匹配。但画标记点将给采集带来额外的麻烦，且会影响到之后人脸材质的估计。
\citet{BeelerHBBBGSG11}通过图像空间跟踪和锚点帧的方法，获取稠密且累积误差小的匹配关系，从而将网格的拓扑结构传播到所有帧，再逐帧根据点云进行微调。
FLAME\citep{FLAME}则完全依靠3D数据，而不使用照片。FLAME是一个由少量PCA得出的参数控制的3D网格模型。它交替地训练该模型和将该配准到3D数据上，从而找到3D数据间的匹配关系。
但3D数据中所包含的信息量有限，因此完全依靠3D的数据的理论精度应不如跟踪图像的方法。
也有一些方法能直接从照片中重建网格，而不需要先得到点云。
\citet{LiLBL0Z21}以传统方法的结果为训练数据，训练一个神经网络，通过体素特征，由粗到细地直接生成网格。

近年来，随着神经辐射场(NeRF)\citep{nerf}等技术的发展，也有一些方法将几何形状编码在神经网络等隐式表达中，而不使用点云、网格等显式表达。
NeRF\citep{nerf}首先提出将几何信息编码在用神经网络表示的密度场中，然后通过体渲染的方法，将渲染结果直接与照片比较，从而优化该模型。
然而，这类隐式模型虽然构建简单，但有诸多问题，例如难以进一步人工编辑，渲染效率较低等。
MoRF\citep{MoRF}通过神经网络生成的形变场以表示人脸几何形状，从而将几何形状和材质分离，提升了可编辑的程度。
\citet{nvdiffrec,nvdiffrecmc}先优化在可变形四面体网格中存储的有向距离场，然后将其转换为传统的显式三角形网格，并使用可微分渲染进一步优化。以此解决隐式模型不易编辑的问题。

\paragraph{相机标定}
精确的相机标定是精确的多视角3D重建的基础。
目前主流的标定方法是用相机拍摄特制的标定目标。
\citet{ss_geo}采用在一个球形目标物体上随机地粘贴一些可识别的角点。
其优势在于不同角度下都能观察到较多角度较正的角点。
\citet{del_grid}提出使用三角形网格代替正方形网格，以在角点处提供更多的梯度信息，从而提升角点定位的精度。
\citet{SchopsLPS20}提出使用大量参数来描述相机模型，且大幅提升标定目标中角点的数量和角点中的梯度信息，从而更精确地估计这些参数。

\paragraph{材质估计}
材质指的是物体的表面法向、颜色、粗糙度、金属度、次表面散射等属性。
更宽泛地说，材质描述了物体将如何与光线相互作用。即如何吸收，折射，反射，散射入射的光线。
若要获得高质量的，可在任意光照条件下渲染的3D模型，则必须对材质进行建模并估计模型参数。

在采集时直接收集多种不同光照条件下的照片的方法称为主动光源方法。
第一代Light Stage\citep{light_stage}使用一个可绕人脸自动旋转的光源，从而获得人脸对各个方向入射光的响应情况，从而实现任意光照条件下的渲染。
此外，该作者还利用色彩空间分析技术\cite{temporal_color}对脸部的法线分布，颜色等属性进行建模，从而实现了任意视角下的渲染。该方法的缺陷在于其单帧图像的采集时间较长。
\citet{MaHPCWD07}通过LED阵列实现的偏振球面梯度照明将所需采集的照片数量减少到了8张，耗时也大幅减少。该方法也通过混合法向模型获得了较为真实的渲染效果，尽管在原理上不太符合物理模型。
此后\citet{KampourisZG18}进一步提出使用球面二值照明和色彩空间分析\cite{MallickZKB05}以分离镜面反射。同时该方法进一步减少了所需采集的照片数量。
\citet{FyffeGTGD16}的方案与本文的方案更为类似。该方法使用了6盏闪光灯并依次在几十毫秒内触发，并用24台相机分布在不同闪光灯闪光时触发快门。该方法可以在近乎瞬间完成6种不同光照的采集，从而避免了被采集对象可能的运动。
\citet{ZhangZZLCYXY22}使用了高达1000FPS的相机，搭配精密控制的LED阵列，实现了在通常一帧的时间内完成数十种不同光照条件的采集。
以上方法使用时域复用的方法来收集多种不同光照条件下的数据，但也有一些方法\citep{FyffeD15,MekaHPZFFKYBDDB19}采用频域复用的方法，即使用可以分别控制不同波长的光的强度的RGB LED灯，在不同频率下实现不同的光照条件。

与之相对的是被动光源方法，即在采集时光照条件保持不变。这类方法的硬件实现通常更为简单。但缺失的信息则需要通过多视角或者更强的正则化等来弥补。
在早期，直接使用照片中的颜色作为漫反射反射率的估计值的方法\citep{PighinHLSS98,BradleyHPS10}比较常见。但这种做法在光源和视角变化时逼真度太低。
\citet{GotardoRBGB18}使用了一个一维子空间来建模人脸在形变过程中反射率的变化，从而大幅限制解空间的维度。但该方法需要在开始阶段让目标缓慢转头采集多帧以初始化该子空间。所以该方法相当于将主动和被动光源相结合。
\citet{RiviereGBGB20}使用了带有次表面散射的材质模型，分别采集了不同偏振方向的数据以更好地分离镜面反射和次表面散射。该方法实现了纹理空间的可微分渲染以估计模型中的参数。
在此基础上，\citet{XuRZCBG22}使用了更准确的偏振模型，光源模型，并建模了部分间接照明效果，使估计的材质参数更加准确。
\citet{nvdiffrec}使用通用的粗糙度-金属度材质模型，利用可微分光栅化渲染技术，联合优化模型的几何形状和材质参数。由于联合优化的难度较高，该方法需要大量的视角作为输入。
本文中的实验平台将会同时支持主动和被动光源方法，以详细探究不同光照条件对重建效果的影响。

除了这些直接描述物理性质的参数化材质模型外，也有研究希望能使用神经网络作为材质模型。
例如NeRF\citep{nerf}也可建模并输出物体反射光线的颜色和强度，且可以建模反射随视角变化的变化，但无法建模与采集时不同的光照条件下的反射情况。
MoRF\citep{MoRF}则通过输出传统着色所需的材质参数，而不是直接输出反射光线，从而能够适应任意新的光照环境。

总结来说，以上这些方法通常使用较为通用，参数量较多的模型，并通过采集尽可能多的数据，通过物理原理来准确估计模型参数，以期尽可能准确的还原采集目标在现实中的样子。

\section{基于自然环境照片的高效3D人脸重建}

除上述这些力求准确的方法外，还有一些方法则希望降低采集的设备成本和复杂度，从而推动3D人脸重建技术在更多领域的应用。
这些方法通常建立在上述高精度方法的基础上，通过采集大量人脸的数据，从中学习并建立更多的关于人脸的先验知识，从而大大降低解空间的维度。
得益于此，甚至可以实现从单张自然环境中拍摄的照片中重建3D人脸。
但相对应地，这些方法重建的结果可能缺失高频信息，或者产生逼真但不准确的结果。

3D可形变模型(3DMM)是这类方法中的先驱者，且这类模型在如今也仍然被广泛使用。
最初\citet{3DMM}利用200个激光扫描的人脸模型，包括人脸的几何和材质，然后认为新的人脸模型可以通过对这些模型进行线性组合来得到。
并且作者将不同人之间的差异通过主成分分析获取其中最重要的部分。
然后作者使用可微分渲染的方法，将该模型与采集到的新的照片进行匹配，并同时估计环境光照的参数，从而实现了从单张照片中重建3D人脸。
该方法仍需要人工指定一个较为准确的初始化。
\citet{deep3d}用已有的人脸关键点识别算法代替人工初始化，并使用可微分渲染来从大量人脸照片中训练神经网络，该网络可实现输入一张照片，直接输出3DMM人脸模型的参数。其最大优势在于，虽然使用神经网络，但无需使用昂贵的大量高精度3D数据进行训练。
DECA\citep{DECA}则在重建FLAME模型的基础上，额外添加了表情相关的动态细节。
\citet{ZielonkaBT22}利用人脸识别算法提取的特征，试图降低人脸远近和大小间的歧义，重建物理尺度更准确的3D人脸模型。
此外，该作者也使用了可微分渲染来捕获输入中的表情，弥补人脸识别对表情的不敏感。
\citet{1022667848.nh,feng2018prn}则选择了不输出3DMM模型的参数，而是直接输出3D人脸模型的顶点坐标。
还有很多方法\citep{GarridoVWT13,CaoBZB15,ShiWTC14,IchimBP15}也是使用类似的思路从单目照片或视频中重建3D人脸，并通过图像中的线索为3DMM模型添加更多细节，使其更加逼真。
\citet{SchonbornEFV15}与本文第\ref{chap:method}章中希望解决的问题类似，希望逆渲染任务能更加适应未知背景的条件，但该作者的思路是对背景应用一个较为通用的模型，且采用的是非基于梯度的方法。
本文将在现有计算可见性梯度的方法的基础上，提出一种无需为背景建模的，适应未知背景的梯度计算方法。

以上方法的输入均是在自然环境下拍摄的照片，其环境光照信息是未知的。
但在实验室的受控环境下，也有一些方法通过数据建立更多的先验知识从而减少所需采集的数据量。
\citet{MekaHPZFFKYBDDB19}通过图片到图片的神经网络，输入两张RGB梯度照明的照片，生成稠密的反射场，从而实现了任意光照条件下的渲染。但该方法作为2D方法，无法简单地扩展到任意视角的3D渲染。且神经网络的输出虽然看上去非常逼真，但在物理上可能不够准确。
\citet{ZhangZZLCYXY22}使用多个VAE分别对采集到的人脸的表情、几何形状、纹理进行解耦、编码和生成，从而实现高效地编辑、驱动所捕获的高精度人脸模型。

\section{可微分渲染}

可微分渲染旨在求解渲染得到的图像关于渲染参数的梯度，以解决逆渲染问题，即从渲染结果的图像中恢复渲染该图像所需的参数。
前述的很多3D人脸重建方法都使用到了可微分渲染相关的技术作为其合成分析方法的一部分，但其运用还很初级。
例如，现有方法均只对每个像素的着色过程计算了梯度，而忽略了几何遮挡等因素。
本文也试图推进更现代的可微分渲染在3D人脸重建中的应用。
下文将介绍通用的可微分渲染领域的一些研究。

\paragraph{基于光线追踪的可微分渲染}
这类方法通过光线追踪的方法，通过蒙特卡洛采样，模拟大量光线在场景中的传播，无偏地估计每个像素的颜色，同时计算该过程的梯度。
这类方法通常计算量较大，且由于随即采样，其估计的梯度具有一定噪声。
\citet{redner}提出了一种使用蒙特卡洛光线追踪的可微分的基于物理的渲染方法，其具有正确的可见性梯度。
Mitsuba 2\citep{Mitsuba2}是一个多功能的渲染框架，可以用于解决各种渲染问题。
它创新性地使用了一种重参数化技术来计算几何遮挡相关的梯度。
\citet{ZeltnerSGJ21}提出将渲染过程和求微分过程的采样解耦，从而降低梯度估计的噪声。

\paragraph{基于光栅化的可微分渲染}
第二类可微分渲染旨在提高性能，以支持合成分析中迭代优化中所需的大量迭代次数。
这类方法基于实时渲染中使用的光栅化渲染方法。
他们主要针对解决形状或姿态估计等任务，它们使用局部信息渲染和着色3D网格，而不考虑全局光照。
这类方法的难点依然是如个计算几何遮挡相关的可见性梯度。
\citet{softras}将每个三角形光栅化为具有可配置模糊半径的概率云，这些云根据其他可配置参数进行启发式组合。这种模糊使覆盖率成为关于顶点位置的连续函数，这对于获得可见性梯度是必要的。
但是，模糊也意味着不透明表面在边缘周围变得透明，从而导致图像不正确。因此需要人工调整这些参数以在图像正确性和梯度质量之间达到平衡。
DIB-R\citep{ChenLGSLJF19}输出一个额外的alpha通道，该通道通过可配置的模糊半径扩展到覆盖像素之外。该alpha通道可用于近似可见性梯度，但仅当参考图像也有alpha遮罩时才能使用。
此外，位于其他几何体前面的轮廓也无法获得可见性梯度。
其模糊半径的参数也需要人工调整。
\citet{KatoUH18}在反向传播过程中基于几何信息在三角形边缘上近似出基于图像的梯度。但是，这些梯度与渲染的图像不一致。
\citet{nvdiffrast}提出了一个模块化的渲染器，其中抗锯齿模块可产生可见性梯度，但它需要处于边缘的三角形正好被渲染到了图像中，否则其产生的梯度就较为稀疏，给优化带来偏差。
\citet{ColeGSVZ21}提出了一种在离散的光栅化算法的基础上解算可见性梯度的方法。该方法也会引入少量模糊。
\citet{LyuHL0TT21}使用球作为代理，为渲染加上了近似的阴影。以更好地拟合目标图像。

\section{基于物理的高质量人脸3D渲染}

若要通过逆渲染的方法，基于可微分渲染重建3D人脸，首先需要一个高质量的3D人脸材质模型和渲染器。
本节将简要介绍计算机图形学业内常用的人脸3D渲染技术。

\paragraph{基于物理的渲染}

在早期的实时3D渲染中，由于计算性能的限制，模型的着色通常是基于一些简单的经验公式的。
而如今，基于物理的渲染(PBR)已经成为了主流，其渲染效果更加逼近真实世界的光照效果。
在基于物理的渲染中，材质模型通常表征了材质的一些物理属性，使其可以直接从现实中测量得到。其渲染方式也是对物理过程更加真实的近似。
这也给从照片进行逆渲染奠定了基础。

其中当前应用较为广泛的模型之一是迪士尼提出的Disney BSDF模型\citep{PBR_disney}。该模型可广泛用于描述生活中的绝大多数材质，包括金属、塑料、玻璃、橡胶、布等。
该模型由迪士尼应用于自己电影的离线渲染中，后被Blender、Unreal Engine等渲染器借鉴。
该模型的参数包括：
基础颜色，表征了材质对不同波长的光的反射率；
金属度，表征了材质是金属或电介质；
粗糙度，表征了材质表面的粗糙程度；
镜面反射，取决于物体的折射率；
以及其他一些共十余个参数。
这些参数也即在3D重建中所需求解的参数。

\paragraph{次表面散射}
除了上述参数外，次表面散射效果在人脸上较为明显，且其渲染较为复杂，因此在此单独介绍。次表面散射是指光线在入射物体之后，在其表面附近多次散射，再从与入射不同的位置出射的现象。

迪士尼介绍了其在离线渲染中使用的模型\citep{SSS_disney}，这是对物理模型的蒙特卡洛模拟数据的数值近似。在离线渲染中，也会直接使用光线追踪对散射现象进行模拟，以达到更逼真的效果。
屏幕空间次表面散射\citep{SSSSS}在实时渲染中应用较广，其直接重用了原本渲染所需计算的数据，从而减小了开销。
纹理空间次表面散射\citep{texSSS}的提出较早，其基本思路是将会发生散射的光线先渲染在纹理空间，然后对其进行多次高斯模糊和叠加，从而计算散射效果。
\citet{SpSSS}提出牺牲一定的角对称性，以提升模糊的计算效率。
Unity3D在其渲染器中也使用了屏幕空间算法\citep{SSS_u3d}，但其实现是基于\citet{SSS_disney}的模型进行随机采样，而非使用高斯模糊近似。

目前离线渲染大多使用光线追踪进行模拟，而实时渲染则使用屏幕空间次表面散射。
但对于多视角3D重建来说，纹理空间的方法或许更加合适，其计算的结果可以被多个视角共享。

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/sss}
    \caption[次表面散射人脸渲染效果]
    {次表面散射人脸渲染效果\citep{SpSSS}。
    在应用次表面散射之前（右下）和之后（右上）的近距离比较。}
\end{figure}

\paragraph{基于图像的光照}

除了对物理本身的建模外，对物体所处环境的准确建模也是逼真渲染的重要一环。
在早期的实时渲染中，通常使用简单的环境光照，点光源，方向光源等解析模型。
但这些模型并不能准确建模采集摄影中使用的柔光箱等设备产生的光照效果。

近年来，基于图像的光照(IBL)技术得到了广泛的应用，其基本思路是将环境光照建模为一个环境贴图，大大提升了光照建模的精度。
\citet{unreal_ssa}介绍了在Unreal Engine中所使用的分离求和近似，使环境贴图作为照明的渲染可以达到实时的效率。
