\chapter{相关研究综述}
\label{chap:related_work}

本章主要介绍本课题的相关研究和实践工作，
其中包括高精度的多视角3D重建方法，
基于少量数据的高效3D人脸重建方法，
可微分渲染以及它在人脸重建中的应用。

\section{多视角3D重建}

这类方法力求通过模型来精确描述被采集对象的形状和材质，从而在重新渲染时表现出很高的逼真度。
这些模型通常能从任意角度，在任意光照环境下重新渲染，以满足影视、游戏等领域的需要。

\begin{figure}
\centering
\begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[height=150pt]{figures/light_stage}
    \caption{实际采集现场}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[height=150pt]{figures/emily_detail_1}
    \caption{重建的几何细节}
\end{subfigure}
\caption[Digital Emily 项目中的 Light Stage]{Digital Emily项目中的Light Stage\cite{DEP}}
\end{figure}

\paragraph{几何形状重建}
几何形状是物体最基本的属性，即物体每个部分在空间中所处的位置。
几何形状重建的基本原理是识别物体同一个部分在不同相机下的匹配关系，然后借助已知的相机参数，以及该部分在不同相机下的像素坐标，计算出该部分在3D空间中的坐标。称为基于视差的方法。

而计算机中描述几何形状的方法有很多种，其中最基本的是点云模型，它保存了大量位于物体表面的点的坐标。
这种表示也是大多数几何重建算法的目标。
最初，\citet{PFM}通过在目标脸上画一些网格，从而允许手动建立格点间的匹配关系，并建立稀疏的点云。
\citet{ss_geo}对多个相机两两之间计算视差图，然后将多组视差图进行融合，并通过约束进一步排除误匹配点，最终得到一个稠密的点云。其中视差图正是两张照片中，像素级别的匹配关系。视差图的构建是分辨率从低到高逐步细化的，并在过程中应用了平滑性、唯一性和顺序性的约束，以消除误匹配点。
这类方法统称为Multi-View Stereo (MVS)。
\citet{DEP}则利用投影仪在目标表面投影彩条图案，以使匹配结果更加鲁棒。
3dMD的商业3D重建解决方案\footnote{https://3dmd.com/}也使用了斑点图案的投影。
D3DFACS\citep{D3DFACS}数据集采用了3dMD的方案。
在匹配过程中，镜面反射的效果会随视角的变化而变化，从而导致匹配结果的不准确。
因此有不少方法\citep{DEP}选择使用偏振将镜面反射的效果去除，从而提高匹配的准确度。
但由于次表面散射的存在，这种方法得到的几何形状会过于平滑。但这或许不是一个问题，因为在后续估计材质的过程中，会再估计更高分辨率的法向。

虽然视差仍然是最广泛使用的方法，其准确度也非常高，但也不乏其他可行的方法。
例如，\citet{MaHPCWD07}使用光度立体的方法，通过多种球面梯度偏振光源的成像效果，重建物体的表面法向。高分辨率的法向信息可与中等分辨率的结构光的结果进行融合，从而获得高分辨率的几何形状，且能避免单纯依靠法线积分带来的累积误差。
\citet{phase_shift}则将相移方法与视差结合，以获得更高的准确度和鲁棒性。
\citet{BJUT3D}选择使用激光扫描仪。
FaceWarehouse\citep{FaceWarehouse}数据集采用了Kinect深度相机。

在得到点云之后，还需要将点云转换为网格，
该网格的拓扑结构应在采集的不同帧间，以及不同人物间保持一致，
以供渲染、人工编辑，动画制作等使用。
该任务的重点在于找到不同帧间的点的匹配关系，从而重建人脸的运动，变形等特征。
很多方法\citep{PFM,DEP,BickelBAMOPG07}通过在脸上画上易于识别的标记点以辅助匹配。但画标记点将给采集带来额外的麻烦，且会影响到之后人脸材质的估计。
\citet{BeelerHBBBGSG11}通过图像空间跟踪和锚点帧的方法，获取稠密且累积误差小的匹配关系，从而将网格的拓扑结构传播到所有帧，再逐帧根据点云进行微调。
FLAME\citep{FLAME}则完全依靠3D数据，而不使用照片。FLAME是一个由少量PCA得出的参数控制的3D网格模型。它交替地训练该模型和将该配准到3D数据上，从而找到3D数据间的匹配关系。
但3D数据中所包含的信息量有限，因此完全依靠3D的数据的理论精度应不如跟踪图像的方法。
也有一些方法能直接从照片中重建网格，而不需要先得到点云。
\citet{LiLBL0Z21}以传统方法的结果为训练数据，训练一个神经网络，通过体素特征，由粗到细地直接生成网格。

近年来，随着神经辐射场(NeRF)\citep{nerf}等技术的发展，也有一些方法将几何形状编码在神经网络等隐式表达中，而不使用点云、网格等显式表达。
NeRF\citep{nerf}首先提出将几何信息编码在用神经网络表示的密度场中，然后通过体渲染的方法，将渲染结果直接与照片比较，从而优化该模型。
然而，这类隐式模型虽然构建简单，但有诸多问题，例如难以进一步人工编辑，渲染效率较低等。
MoRF\citep{MoRF}通过神经网络生成的形变场以表示人脸几何形状，从而将几何形状和材质分离，提升了可编辑的程度。
\citet{nvdiffrec,nvdiffrecmc}先优化在可变形四面体网格中存储的有向距离场，然后将其转换为传统的显式三角形网格，并使用可微分渲染进一步优化。以此解决隐式模型不易编辑的问题。

\paragraph{相机标定}
精确的相机标定是精确的多视角3D重建的基础。
目前主流的标定方法是用相机拍摄特制的标定目标。
\citet{ss_geo}采用在一个球形目标物体上随机地粘贴一些可识别的角点。
其优势在于不同角度下都能观察到较多角度较正的角点。
\citet{del_grid}提出使用三角形网格代替正方形网格，以在角点处提供更多的梯度信息，从而提升角点定位的精度。
\citet{SchopsLPS20}提出使用大量参数来描述相机模型，且大幅提升标定目标中角点的数量和角点中的梯度信息，从而更精确地估计这些参数。

\paragraph{材质估计}
材质指的是物体的表面法向、颜色、粗糙度、金属度、次表面散射等属性。
更宽泛地说，材质描述了物体将如何与光线相互作用。即如何吸收，折射，反射，散射入射的光线。
若要获得高质量的，可在任意光照条件下渲染的3D模型，则必须对材质进行建模并估计模型参数。

在采集时直接收集多种不同光照条件下的照片的方法称为主动光源方法。
第一代Light Stage\citep{light_stage}使用一个可绕人脸自动旋转的光源，从而获得人脸对各个方向入射光的响应情况，从而实现任意光照条件下的渲染。
此外，该作者还利用色彩空间分析技术\cite{temporal_color}对脸部的法线分布，颜色等属性进行建模，从而实现了任意视角下的渲染。该方法的缺陷在于其单帧图像的采集时间较长。
\citet{MaHPCWD07}通过LED阵列实现的偏振球面梯度照明将所需采集的照片数量减少到了8张，耗时也大幅减少。该方法也通过混合法向模型获得了较为真实的渲染效果，尽管在原理上不太符合物理模型。
此后\citet{KampourisZG18}进一步提出使用球面二值照明和色彩空间分析\cite{MallickZKB05}以分离镜面反射。同时该方法进一步减少了所需采集的照片数量。
\citet{FyffeGTGD16}的方案与本文的方案更为类似。该方法使用了6盏闪光灯并依次在几十毫秒内触发，并用24台相机分布在不同闪光灯闪光时触发快门。该方法可以在近乎瞬间完成6种不同光照的采集，从而避免了被采集对象可能的运动。
\citet{ZhangZZLCYXY22}使用了高达1000FPS的相机，搭配精密控制的LED阵列，实现了在通常一帧的时间内完成数十种不同光照条件的采集。
以上方法使用时域复用的方法来收集多种不同光照条件下的数据，但也有一些方法\citep{FyffeD15,MekaHPZFFKYBDDB19}采用频域复用的方法，即使用可以分别控制不同波长的光的强度的RGB LED灯，在不同频率下实现不同的光照条件。

与之相对的是被动光源方法，即在采集时光照条件保持不变。这类方法的硬件实现通常更为简单。但缺失的信息则需要通过多视角或者更强的正则化等来弥补。
在早期，直接使用照片中的颜色作为漫反射反射率的估计值的方法\citep{PighinHLSS98,BradleyHPS10}比较常见。但这种做法在光源和视角变化时逼真度太低。
\citet{GotardoRBGB18}使用了一个一维子空间来建模人脸在形变过程中反射率的变化，从而大幅限制解空间的维度。但该方法需要在开始阶段让目标缓慢转头采集多帧以初始化该子空间。所以该方法相当于将主动和被动光源相结合。
\citet{RiviereGBGB20}使用了带有次表面散射的材质模型，分别采集了不同偏振方向的数据以更好地分离镜面反射和次表面散射。该方法实现了纹理空间的可微分渲染以估计模型中的参数。
在此基础上，\citet{XuRZCBG22}使用了更准确的偏振模型，光源模型，并建模了部分间接照明效果，使估计的材质参数更加准确。
\citet{nvdiffrec}使用通用的粗糙度-金属度材质模型，利用可微分光栅化渲染技术，联合优化模型的几何形状和材质参数。由于联合优化的难度较高，该方法需要大量的视角作为输入。
本文中的实验平台将会同时支持主动和被动光源方法，以详细探究不同光照条件对重建效果的影响。

除了这些直接描述物理性质的参数化材质模型外，也有研究希望能使用神经网络作为材质模型。
例如NeRF\citep{nerf}也可建模并输出物体反射光线的颜色和强度，且可以建模反射随视角变化的变化，但无法建模与采集时不同的光照条件下的反射情况。
MoRF\citep{MoRF}则通过输出传统着色所需的材质参数，而不是直接输出反射光线，从而能够适应任意新的光照环境。

总结来说，以上这些方法通常使用较为通用，参数量较多的模型，并通过采集尽可能多的数据，通过物理原理来准确估计模型参数，以期尽可能准确的还原采集目标在现实中的样子。

\section{高效3D人脸重建}

除上述这些力求准确的方法外，还有一些方法则希望降低采集的设备成本和复杂度，从而推动3D人脸重建技术在更多领域的应用。
这些方法通常建立在上述高精度方法的基础上，通过采集大量人脸的数据，从中学习并建立更多的关于人脸的先验知识，从而大大降低解空间的维度。
得益于此，甚至可以实现从单张自然环境中拍摄的照片中重建3D人脸。
但相对应地，这些方法重建的结果可能缺失高频信息，或者产生逼真但不准确的结果。

3D可形变模型(3DMM)是这类方法中的先驱者，且这类模型在如今也仍然被广泛使用。
最初\citet{3DMM}利用200个激光扫描的人脸模型，包括人脸的几何和材质，然后认为新的人脸模型可以通过对这些模型进行线性组合来得到。
并且作者将不同人之间的差异通过主成分分析获取其中最重要的部分。
然后作者使用可微分渲染的方法，将该模型与采集到的新的照片进行匹配，并同时估计环境光照的参数，从而实现了从单张照片中重建3D人脸。
该方法仍需要人工指定一个较为准确的初始化。
\citet{deep3d}用已有的人脸关键点识别算法代替人工初始化，并使用可微分渲染来从大量人脸照片中训练神经网络，该网络可实现输入一张照片，直接输出3DMM人脸模型的参数。其最大优势在于，虽然使用神经网络，但无需使用昂贵的大量高精度3D数据进行训练。
DECA\citep{DECA}则在重建FLAME模型的基础上，额外添加了表情相关的动态细节。
\citet{ZielonkaBT22}利用人脸识别算法提取的特征，试图降低人脸远近和大小间的歧义，重建物理尺度更准确的3D人脸模型。
此外，该作者也使用了可微分渲染来捕获输入中的表情，弥补人脸识别对表情的不敏感。
还有很多方法\citep{GarridoVWT13,CaoBZB15,ShiWTC14,IchimBP15}也是使用类似的思路从单目照片或视频中重建3D人脸，并通过图像中的线索为3DMM模型添加更多细节，使其更加逼真。

以上方法的输入均是在自然环境下拍摄的照片，其环境光照信息是未知的。
但在实验室的受控环境下，也有一些方法通过数据建立更多的先验知识从而减少所需采集的数据量。
\citet{MekaHPZFFKYBDDB19}通过图片到图片的神经网络，输入两张RGB梯度照明的照片，生成稠密的反射场，从而实现了任意光照条件下的渲染。但该方法作为2D方法，无法简单地扩展到任意视角的3D渲染。且神经网络的输出虽然看上去非常逼真，但在物理上可能不够准确。
\citet{ZhangZZLCYXY22}使用多个VAE分别对采集到的人脸的表情、几何形状、纹理进行解耦、编码和生成，从而实现高效地编辑、驱动所捕获的高精度人脸模型。


\section{可微分渲染}

\section{高质量人脸3D渲染}

\paragraph{基于物理的渲染}

\paragraph{分离求和近似}

\paragraph{次表面散射}
